{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This file is expected to be ran after persistent homology features have been created in \n",
    "a (default) folder structure like:\n",
    "\n",
    "/complete_data\n",
    "    /sample_1\n",
    "        /clique_dictionaries\n",
    "        /gen\n",
    "        /edge_vals\n",
    "    /sample_2\n",
    "        ...\n",
    "    ...\n",
    "\n",
    "This file takes a MatLab array sub_i_sess_j.mat representing the data obtained from subject i during session j\n",
    "The MatLab array file is expected to have target-class field 'fMRI_labels_selected_thresh' used for classification.\n",
    "\n",
    "In this analysis, we only use the 1st homology dimension.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from os.path import join\n",
    "import pickle as pickle\n",
    "import pickle as pk\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from scipy.io import loadmat\n",
    "from compute_PH_features import get_birth_and_death\n",
    "import Holes as ho\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "\n",
    "def load_feature_data(sample_data_pths):\n",
    "    \"\"\"\n",
    "    Load the features and target data into a dictionary \n",
    "    \"\"\"\n",
    "    feature_data = {}\n",
    "    target_counter = 0\n",
    "    for dp in sample_data_pths:\n",
    "        sample_idx = int(dp.split('/')[-1].split('_')[1])\n",
    "        gen_pth = join(dp, 'gen')\n",
    "        feature_data[sample_idx] = {}.fromkeys(['raw_pth', 'target_cls'])\n",
    "        feature_data[sample_idx]['raw_pth'] = [join(gen_pth, x) for x in os.listdir(gen_pth)]\n",
    "        feature_data[sample_idx]['target_cls'] = targets[target_counter]\n",
    "        target_counter += 1\n",
    "    return feature_data\n",
    "\n",
    "def check_keys(feature_data, targets):\n",
    "    \"\"\"\n",
    "    Check to make sure we have the same number of samples as trials\n",
    "    \"\"\"\n",
    "    keys = feature_data.keys()\n",
    "    for i in range(targets.shape[0]):\n",
    "        try:\n",
    "            assert i in keys\n",
    "        except AssertionError:\n",
    "            raise RuntimeError(\"There isn't the same number of generated feature \"\n",
    "                               \"sets as there are trials. Please investigate!\")\n",
    "\n",
    "def get_barcode(gen_lst, title=''):\n",
    "    return ho.barcode_creator(gen_lst, title=title)\n",
    "\n",
    "\n",
    "def summary(gen_lst, homology_group=1):\n",
    "    return gen_lst[homology_group].summary()\n",
    "\n",
    "\n",
    "def get_features_and_target_data(feature_data_pths, hom_dim=1):\n",
    "    feature_data_array = {}\n",
    "    target_data_array = {}\n",
    "    \n",
    "    for sample in feature_data_pths.keys():\n",
    "        sample_gens_per_time_window = feature_data_pths[sample]['raw_pth']  \n",
    "        feature_data_array[sample] = []\n",
    "        for gen_pth in sample_gens_per_time_window:\n",
    "            generators = pickle.load(open(gen_pth, 'r'))\n",
    "            feature_data_array[sample].append(generators[hom_dim]) # 1 for H1 group\n",
    "\n",
    "        target_data = feature_data_pths[sample]['target_cls']\n",
    "        target_data_array[sample] = target_data  # H1 group\n",
    "            \n",
    "    return feature_data_array, target_data_array\n",
    "\n",
    "# def get_features_and_target_data(feature_data_pths, hom_dim=1):\n",
    "#     \"\"\"\n",
    "#     Load the training and target data for a particular homology dimension\n",
    "#     \"\"\"\n",
    "#     feature_data_array = {}\n",
    "#     target_data_array = {}\n",
    "    \n",
    "#     def get_persistence_lifetime(cycle):\n",
    "#         return float(cycle.end) - float(cycle.start)\n",
    "    \n",
    "#     def pad(lst, ln):\n",
    "#         if len(lst) < ln:\n",
    "#             diff = ln - len(lst)\n",
    "#             pad = [0]*diff\n",
    "#             lst += pad\n",
    "#         return lst\n",
    "\n",
    "#     for sample in feature_data_pths.keys():\n",
    "#         sample_gens_per_time_window = feature_data_pths[sample]['raw_pth']\n",
    "#         sample_feature_data = []  # [births, deaths, num_time_windows]\n",
    "#         for gen_pth in sample_gens_per_time_window:\n",
    "#             time_window_birth_deaths = []\n",
    "            \n",
    "#             feature_data = pickle.load(open(gen_pth, 'r'))\n",
    "#             sample_cycles = feature_data[hom_dim]\n",
    "            \n",
    "#             for cycle in sample_cycles:\n",
    "#                 cycle_lifetime = get_persistence_lifetime(cycle)\n",
    "#                 sample_feature_data.append((cycle, cycle_lifetime))  # H1 group\n",
    "                \n",
    "#         sorted_feature_data = [[float(i[0].start), float(i[0].end)] for i in sorted(sample_feature_data, key=lambda x:x[1])] # sort by ascending lifetime\n",
    "#         feature_data_array[sample] = sorted_feature_data\n",
    "#         target_data = feature_data_pths[sample]['target_cls']\n",
    "#         target_data_array[sample] = target_data \n",
    "\n",
    "\n",
    "#     for sample in feature_data_pths.keys():\n",
    "        \n",
    "\n",
    "#     return feature_data_array, target_data_array\n",
    "\n",
    "\n",
    "def show_persistence_across_trial(gens):\n",
    "    \"\"\"\n",
    "    Plot the persistence diagrams of a given trial. Since each trial \n",
    "    has multiple windows, and thus multiple generators, shows the change \n",
    "    within one trial.\n",
    "    \"\"\"\n",
    "    for i in gens:\n",
    "        get_barcode(i)\n",
    "\n",
    "\n",
    "def get_summaries_across_trial(gens):\n",
    "    for i in gens:\n",
    "        summary(i)\n",
    "\n",
    "def get_feature_data_with_targets(feature_data_array):\n",
    "    \"\"\"\n",
    "    Get complete training data with targets\n",
    "    \"\"\"\n",
    "    train_x = []\n",
    "    max_bi = 0\n",
    "\n",
    "    for sample in feature_data_array.keys():\n",
    "        sample_data = []  # [[[b,d] x 14] x n] --> n x 14 x max({b}) x max({d})\n",
    "        for gen_file in feature_data_array[sample]:\n",
    "            b, d = get_birth_and_death(gen_file)\n",
    "            if len(b) > max_bi:\n",
    "                max_bi = len(b)\n",
    "            sample_data.append([b, d])\n",
    "        train_x.append(sample_data)\n",
    "\n",
    "    print \"max b_i is: {0}\".format(max_bi)\n",
    "    print \"Number of samples is: {0}\".format(len(train_x))\n",
    "    return train_x, max_bi\n",
    "\n",
    "def get_sample_data(train_x, max_bi):\n",
    "    \"\"\"\n",
    "    Get train_x max dimensions\n",
    "    Each sample n_i has features --> 14 x 2 x max{b+i} where max{b_i} is max over all samples\n",
    "    \"\"\"\n",
    "    padded_train_x = np.zeros((len(train_x), 14 * 2 * max_bi))\n",
    "    sample_array_template = np.zeros((14, 2, max_bi))\n",
    "    i = 0\n",
    "    for sample in train_x:\n",
    "        j = 0\n",
    "        for gen_window in sample:  # 14 of these\n",
    "            b, d = gen_window\n",
    "            # Pad b and d\n",
    "            b_pad = pad(b, max_bi)\n",
    "            d_pad = pad(d, max_bi)\n",
    "            sample_features = deepcopy(sample_array_template)\n",
    "            sample_features[j][0][0:] = b_pad\n",
    "            sample_features[j][1][0:] = d_pad\n",
    "            j += 1\n",
    "        # Reshape\n",
    "        sample_features = sample_features.reshape(1, -1)\n",
    "        padded_train_x[i][0:] = sample_features\n",
    "        i += 1\n",
    "    return padded_train_x\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "\n",
    "    \"\"\"\n",
    "    Path parameters\n",
    "    \"\"\"\n",
    "    data_pth = 'data/completed_data/'\n",
    "    repo_dir = os.getcwd()\n",
    "    subject_1_session_1_pth = join(repo_dir, 'data/raw_data/sub1_ses1.mat')\n",
    "    \"\"\"\n",
    "    Load Data\n",
    "    \"\"\"\n",
    "    sample_data_pths = [join(data_pth, x) for x in os.listdir(data_pth)]\n",
    "    mat = loadmat(subject_1_session_1_pth)  # load mat-file\n",
    "    targets = mat['fMRI_labels_selected_thresh']\n",
    "    feature_data_pths = load_feature_data(sample_data_pths)\n",
    "    check_keys(feature_data_pths, targets)\n",
    "    feature_data_array, target_data_array = get_features_and_target_data(feature_data_pths)\n",
    "\n",
    "    train_x, max_bi = get_feature_data_with_targets(feature_data_array)\n",
    "    sample_features = get_sample_data(train_x, max_bi)\n",
    "    \"\"\"\n",
    "    Get train_y\n",
    "    \"\"\"\n",
    "    train_y = np.array(target_data_array.values()[0:len(train_x)])\n",
    "    \"\"\"\n",
    "    Get padded_train_x\n",
    "    \"\"\"\n",
    "    padded_train_x = get_sample_data(train_x, max_bi)\n",
    "    print \"padded train_x shape is: {0}\".format(padded_train_x.shape)\n",
    "    print \"train_y shape is: {0}\".format(train_y.shape)\n",
    "    \"\"\"\n",
    "    Perform prediction\n",
    "    \"\"\"\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(500, 250, 100, 50), max_iter=100000, )\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(padded_train_x, train_y, test_size=0.33, random_state=42)\n",
    "    t1 = time.time()\n",
    "    mlp.fit(X_train, y_train)\n",
    "    t2 = time.time()\n",
    "    print (t2 - t1)\n",
    "    preds = mlp.predict(X_test) \n",
    "    print \"preds shape is:{0}\".format(preds.shape)\n",
    "    print classification_report(y_test, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
